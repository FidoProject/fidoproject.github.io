<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>Fido: Software/QLearn.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="17830624.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">Fido
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_4e9c05acfa2c3671b8618fcb95d57d96.html">Software</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">QLearn.h</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef QLEARN_H</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor"></span><span class="preprocessor">#define QLEARN_H</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="preprocessor"></span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &quot;Backpropagation.h&quot;</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="keyword">namespace </span>net {</div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;    </div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;    <span class="keyword">class </span>NeuralNet;</div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;</div>
<div class="line"><a name="l00012"></a><span class="lineno"><a class="line" href="classnet_1_1_q_learn.html">   12</a></span>&#160;    <span class="keyword">class </span><a class="code" href="classnet_1_1_q_learn.html">QLearn</a> {</div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;    <span class="keyword">public</span>:</div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;        std::vector&lt;NeuralNet *&gt; networks;</div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;        <a class="code" href="classnet_1_1_backpropagation.html">Backpropagation</a> backprop;</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;        <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> lastAction, numberOfActions;</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;        <span class="keywordtype">double</span> learningRate, devaluationFactor;</div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;        <span class="keywordtype">double</span> lastReward;</div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;        std::vector&lt;double&gt; lastState;</div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;        std::vector&lt; std::vector&lt; std::pair&lt;std::vector&lt;double&gt;, <span class="keywordtype">double</span>&gt; &gt; &gt; history;</div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;        <span class="comment">/* Initializes a QLearn object with a model network and the values of learning rate and devaluationFactor.</span></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="comment">         *</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="comment">         * The model network is used as a model architecture for the networks that will rate the reward of each action.</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="comment">         * Learning rate is a constant between 0 and 1 that dictates how fast the robot learns from reinforcement.</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="comment">         * Devaluation factor is a constant between 0 and 1 that weighs future reward vs immediate reward. </span></div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="comment">         * A value of 0 will make the network only value immediate reward, while a value of 1 will make it consider future reward with the same weight as immediate reward. </span></div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="comment">         */</span></div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;        <a class="code" href="classnet_1_1_q_learn.html">QLearn</a>(<a class="code" href="classnet_1_1_neural_net.html">NeuralNet</a> *modelNetwork, <a class="code" href="classnet_1_1_backpropagation.html">Backpropagation</a> backprop_, <span class="keywordtype">double</span> learningRate_, <span class="keywordtype">double</span> devaluationFactor_, <span class="keywordtype">int</span> numberOfActions_);</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;</div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;        <span class="comment">/* Initializes a QLearn object with an vector of networks and the values of learning rate and devaluationFactor.</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="comment">        *</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="comment">        * The vector of networks contains the networks that will rate the reward of each action</span></div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="comment">        * Learning rate is a constant between 0 and 1 that dictates how fast the robot learns from reinforcement.</span></div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="comment">        * Devaluation factor is a constant between 0 and 1 that weighs future reward vs immediate reward.</span></div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="comment">        * A value of 0 will make the network only value immediate reward, while a value of 1 will make it consider future reward with the same weight as immediate reward.</span></div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="comment">        */</span></div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;        <a class="code" href="classnet_1_1_q_learn.html">QLearn</a>(std::vector&lt;NeuralNet *&gt; networks_, <a class="code" href="classnet_1_1_backpropagation.html">Backpropagation</a> backprop_, <span class="keywordtype">double</span> learningRate_, <span class="keywordtype">double</span> devaluationFactor_);</div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;</div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;        <span class="comment">// Initializes a QLearn object with a file that contains a stored QLearn object</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;        <a class="code" href="classnet_1_1_q_learn.html">QLearn</a>(std::string filename);</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;        <span class="comment">// Initialize empty QLearn object</span></div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;        <a class="code" href="classnet_1_1_q_learn.html">QLearn</a>();</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;        <span class="comment">// Gets the action that the network deems most benificial for the currentState</span></div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> chooseBestAction(std::vector&lt;double&gt; currentState);</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;        <span class="comment">/* Gets an action using the Boltzman softmax probability distribution</span></div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="comment">         *</span></div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="comment">         * Non-random search heuristic used so that the neural network explores actions despite their reward value. </span></div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="comment">         * The lower the exploration constanstant, the more likely it is to pick the best action for the current state.</span></div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="comment">         */</span></div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;        <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="classnet_1_1_q_learn.html#adb6e07fd14e98663e4560aa6fc00bf83">chooseBoltzmanAction</a>(std::vector&lt;double&gt; currentState, <span class="keywordtype">double</span> explorationConstant);</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;        <span class="comment">/* Given the immediate reward from the last action taken and the new state, </span></div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="comment">         * this function updates the correct value for the longterm reward of the lastAction and trains the network in charge of the lastAction to output the corect reward value</span></div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment">         */</span></div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;        <span class="keywordtype">void</span> applyReinforcementToLastAction(<span class="keywordtype">double</span> reward, std::vector&lt;double&gt; newState);</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;        <span class="keywordtype">void</span> storeQLearn(std::string filename);</div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;    <span class="keyword">private</span>:</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;        <span class="comment">// Gets the action with the highest reward for a state and gets that action&#39;s reward</span></div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;        <span class="keywordtype">void</span> getBestActionAndReward(std::vector&lt;double&gt; state, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *bestAction, <span class="keywordtype">double</span> *bestReward);</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;        <span class="comment">// Returns the reward value of the action with the greatest reward.</span></div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;        <span class="keywordtype">double</span> highestReward(std::vector&lt;double&gt; state);</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;        <span class="comment">// Returns the action with the highest reward</span></div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;        <span class="keywordtype">int</span> bestAction(std::vector&lt;double&gt; state);</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    };</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;};</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="ttc" id="classnet_1_1_neural_net_html"><div class="ttname"><a href="classnet_1_1_neural_net.html">net::NeuralNet</a></div><div class="ttdef"><b>Definition:</b> NeuralNet.h:16</div></div>
<div class="ttc" id="classnet_1_1_backpropagation_html"><div class="ttname"><a href="classnet_1_1_backpropagation.html">net::Backpropagation</a></div><div class="ttdef"><b>Definition:</b> Backpropagation.h:14</div></div>
<div class="ttc" id="classnet_1_1_q_learn_html"><div class="ttname"><a href="classnet_1_1_q_learn.html">net::QLearn</a></div><div class="ttdef"><b>Definition:</b> QLearn.h:12</div></div>
<div class="ttc" id="classnet_1_1_q_learn_html_adb6e07fd14e98663e4560aa6fc00bf83"><div class="ttname"><a href="classnet_1_1_q_learn.html#adb6e07fd14e98663e4560aa6fc00bf83">net::QLearn::chooseBoltzmanAction</a></div><div class="ttdeci">unsigned int chooseBoltzmanAction(std::vector&lt; double &gt; currentState, double explorationConstant)</div><div class="ttdef"><b>Definition:</b> QLearn.cpp:62</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Mar 18 2016 00:52:30 for Fido by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.6
</small></address>
</body>
</html>
